{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "english_data = \"data/hansards.e\"\n",
    "french_data = \"data/hansards.f\"\n",
    "\n",
    "english_words = []\n",
    "french_words = []\n",
    "sentence_pairs = []\n",
    "\n",
    "for english_line, french_line in zip(open(english_data), open(french_data)): # open english and french text\n",
    "    sentence_pairs.append([english_line.strip().split(), french_line.strip().split()]) # append english-french sentence pairs to list\n",
    "                                    \n",
    "    for english in english_line.strip().split(): # strip whitespaces and split english string into a list\n",
    "        english_words.append(english) # append english words to list\n",
    "    for french in french_line.strip().split(): # strip whitespaces and split french string into a list\n",
    "        french_words.append(french) # append french words to list\n",
    "\n",
    "english_words = list(set(english_words)) # convert lists to sets to get unique words \n",
    "french_words = list(set(french_words)) \n",
    "\n",
    "english_words_i = {english:i for i,english in enumerate(english_words)} # get positions of words in lists \n",
    "french_words_i = {french:i for i,french in enumerate(french_words)} \n",
    "\n",
    "trans_prob = np.ones([len(english_words), len(french_words)], dtype = np.float32) # initialize translation probabilities \n",
    "trans_prob = trans_prob/len(english_words) # divide translation probabilities by length of english words\n",
    "\n",
    "for i in range (0,5):\n",
    "\n",
    "    count_pair = np.zeros([len(english_words), len(french_words)], dtype = np.float32) # initialize counts to zero\n",
    "    count_french = np.zeros([1,len(french_words)], dtype = np.float32) \n",
    "\n",
    "    for english, french in sentence_pairs:\n",
    "        index_e = [english_words_i[k] for k in english] # get indices of words\n",
    "        index_f = [french_words_i[k] for k in french]\n",
    "        sub_array = trans_prob[np.ix_(index_e,index_f)].copy() \n",
    "        norm = sub_array/sub_array.sum(axis = 1).reshape(-1,1)\n",
    "        count_pair[np.ix_(index_e, index_f)] = count_pair[np.ix_(index_e, index_f)] + norm\n",
    "        count_french[:,np.ix_(index_f)] = count_french[:,np.ix_(index_f)] + norm.sum(axis = 0)\n",
    "        \n",
    "    trans_prob = count_pair /count_french\n",
    "\n",
    "for (e_w, f_w) in sentence_pairs: # alignment\n",
    "    for (i, f_i) in enumerate(f_w):\n",
    "        best_prob = 0\n",
    "        best_j = 0\n",
    "        for (j, e_j) in enumerate(e_w):\n",
    "            if trans_prob[english_words_i[e_j],french_words_i[f_i]] > best_prob:\n",
    "                best_prob = trans_prob[english_words_i[e_j],french_words_i[f_i]]\n",
    "                best_j = j\n",
    "        sys.stdout.write(\"%i-%i \" % (i,best_j))\n",
    "    sys.stdout.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
